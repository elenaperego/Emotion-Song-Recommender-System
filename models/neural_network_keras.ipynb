{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/kvsingh/music-mood-classification\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import spotify_lyrics_scraper as spotify\n",
    "\n",
    "# Get the SP_DC token\n",
    "token = spotify.getToken(\"AQBSz33_ODmldHiskIdlUiuu4yS92-tR4swS5FeqJuHYfBNUdEs3j0mWK4Hmo9wDc3eTK6IRAE0xFoXnH94CkXHKUWvZuFLTdTxyBdOhLCtSyhZLRWM21tgwJDAI1MxFAA_dEPWMtVMxGd9GefWoL4JbtxCXlsfKvk0CF5zpBQ1m_JskXi7hHLj-wLJBlNdTlpdkeA_LZwBCZG5yQowbiE4hO8K5\")\n",
    "\n",
    "def get_lyrics(song_name):\n",
    "    lyrics_data = spotify.getLyrics(token, songName=song_name)\n",
    "    if lyrics_data['status']:\n",
    "        lyrics_lines = lyrics_data['message']['lyrics']['lines']\n",
    "        lyrics = \" \".join([line['words'] for line in lyrics_lines])\n",
    "        return lyrics\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Add a new column with the lyrics\n",
    "df['lyrics'] = df['name'].apply(lambda x: get_lyrics(x))\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Define the emotions\n",
    "emotions = [\n",
    "    'happy',\n",
    "    'anger',\n",
    "    'fear',\n",
    "    'surprise',\n",
    "    'sadness',\n",
    "    'disgust'\n",
    "]\n",
    "\n",
    "def get_emotion_probabilities(lyrics):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(lyrics, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "    # Get the model outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Extract logits and compute probabilities\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=1)[0]\n",
    "\n",
    "    # Map emotions to probabilities\n",
    "    emotion_probs = {emotion: float(probabilities[idx]) for idx, emotion in enumerate(emotions)}\n",
    "    return emotion_probs\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('../songs/data_moods.csv')\n",
    "\n",
    "# Combine all the lyrics lines into a single string for each song and get emotion probabilities\n",
    "df['emotion_probabilities'] = df['lyrics'].apply(lambda x: get_emotion_probabilities(x))\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df.to_csv('../songs/data_moods.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>popularity</th>\n",
       "      <th>length</th>\n",
       "      <th>danceability</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>key</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>1999</td>\n",
       "      <td>Prince</td>\n",
       "      <td>2H7PHVdQ3mXqEHXcvclTB0</td>\n",
       "      <td>1982-10-27</td>\n",
       "      <td>68</td>\n",
       "      <td>379266</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.13700</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>-8.201</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>118.523</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>Blonde Redhead</td>\n",
       "      <td>4HIwL9ii9CcXpTOTzMq0MP</td>\n",
       "      <td>2007-04-16</td>\n",
       "      <td>43</td>\n",
       "      <td>318800</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.01890</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>-5.069</td>\n",
       "      <td>0.0492</td>\n",
       "      <td>120.255</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9 Crimes</td>\n",
       "      <td>9</td>\n",
       "      <td>Damien Rice</td>\n",
       "      <td>5GZEeowhvSieFDiR8fQ2im</td>\n",
       "      <td>2006-11-06</td>\n",
       "      <td>60</td>\n",
       "      <td>217946</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.91300</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.0934</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>-15.326</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>136.168</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99 Luftballons</td>\n",
       "      <td>99 Luftballons</td>\n",
       "      <td>Nena</td>\n",
       "      <td>6HA97v4wEGQ5TUClRM0XLc</td>\n",
       "      <td>1984-08-21</td>\n",
       "      <td>2</td>\n",
       "      <td>233000</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.08900</td>\n",
       "      <td>0.4380</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>-12.858</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>193.100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Boy Brushed Red Living In Black And White</td>\n",
       "      <td>They're Only Chasing Safety</td>\n",
       "      <td>Underoath</td>\n",
       "      <td>47IWLfIKOKhFnz1FUEUIkE</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>60</td>\n",
       "      <td>268000</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.00171</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>-3.604</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>169.881</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Energetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>windcatcher</td>\n",
       "      <td>windcatcher</td>\n",
       "      <td>Leo Nocta</td>\n",
       "      <td>59VApBbrS2IADQk4ml5mdo</td>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>36</td>\n",
       "      <td>123066</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.96100</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.919000</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>-20.615</td>\n",
       "      <td>0.0603</td>\n",
       "      <td>129.736</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>yellow is the color of her eyes</td>\n",
       "      <td>yellow is the color of her eyes</td>\n",
       "      <td>Soccer Mommy</td>\n",
       "      <td>4D3nttJPU6L0M2epr7sId6</td>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>5</td>\n",
       "      <td>435080</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.75700</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>-7.351</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>80.537</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>you broke me first</td>\n",
       "      <td>you broke me first</td>\n",
       "      <td>Tate McRae</td>\n",
       "      <td>45bE4HXI0AwGZXfZtMp8JR</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>87</td>\n",
       "      <td>169265</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.78600</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.0799</td>\n",
       "      <td>-9.386</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>124.099</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>you were good to me</td>\n",
       "      <td>brent</td>\n",
       "      <td>Jeremy Zucker</td>\n",
       "      <td>4CxFN5zON70B3VOPBYbd6P</td>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>76</td>\n",
       "      <td>219146</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.91300</td>\n",
       "      <td>0.0848</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>-15.099</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>102.128</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>æfre</td>\n",
       "      <td>æfre</td>\n",
       "      <td>praam</td>\n",
       "      <td>2irbT1BSYaIEF44PlyKaoM</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>41</td>\n",
       "      <td>186331</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.0804</td>\n",
       "      <td>-28.435</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>140.179</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            name  \\\n",
       "0                                           1999   \n",
       "1                                             23   \n",
       "2                                       9 Crimes   \n",
       "3                                 99 Luftballons   \n",
       "4    A Boy Brushed Red Living In Black And White   \n",
       "..                                           ...   \n",
       "681                                  windcatcher   \n",
       "682              yellow is the color of her eyes   \n",
       "683                           you broke me first   \n",
       "684                          you were good to me   \n",
       "685                                         æfre   \n",
       "\n",
       "                               album          artist                      id  \\\n",
       "0                               1999          Prince  2H7PHVdQ3mXqEHXcvclTB0   \n",
       "1                                 23  Blonde Redhead  4HIwL9ii9CcXpTOTzMq0MP   \n",
       "2                                  9     Damien Rice  5GZEeowhvSieFDiR8fQ2im   \n",
       "3                     99 Luftballons            Nena  6HA97v4wEGQ5TUClRM0XLc   \n",
       "4        They're Only Chasing Safety       Underoath  47IWLfIKOKhFnz1FUEUIkE   \n",
       "..                               ...             ...                     ...   \n",
       "681                      windcatcher       Leo Nocta  59VApBbrS2IADQk4ml5mdo   \n",
       "682  yellow is the color of her eyes    Soccer Mommy  4D3nttJPU6L0M2epr7sId6   \n",
       "683               you broke me first      Tate McRae  45bE4HXI0AwGZXfZtMp8JR   \n",
       "684                            brent   Jeremy Zucker  4CxFN5zON70B3VOPBYbd6P   \n",
       "685                             æfre           praam  2irbT1BSYaIEF44PlyKaoM   \n",
       "\n",
       "    release_date  popularity  length  danceability  acousticness  energy  \\\n",
       "0     1982-10-27          68  379266         0.866       0.13700  0.7300   \n",
       "1     2007-04-16          43  318800         0.381       0.01890  0.8320   \n",
       "2     2006-11-06          60  217946         0.346       0.91300  0.1390   \n",
       "3     1984-08-21           2  233000         0.466       0.08900  0.4380   \n",
       "4     2004-01-01          60  268000         0.419       0.00171  0.9320   \n",
       "..           ...         ...     ...           ...           ...     ...   \n",
       "681   2020-06-19          36  123066         0.402       0.96100  0.2360   \n",
       "682   2019-11-19           5  435080         0.452       0.75700  0.5150   \n",
       "683   2020-04-17          87  169265         0.642       0.78600  0.3740   \n",
       "684   2019-05-03          76  219146         0.561       0.91300  0.0848   \n",
       "685   2020-07-17          41  186331         0.377       0.99400  0.0156   \n",
       "\n",
       "     instrumentalness  liveness  valence  loudness  speechiness    tempo  key  \\\n",
       "0            0.000000    0.0843   0.6250    -8.201       0.0767  118.523    5   \n",
       "1            0.196000    0.1530   0.1660    -5.069       0.0492  120.255    8   \n",
       "2            0.000077    0.0934   0.1160   -15.326       0.0321  136.168    0   \n",
       "3            0.000006    0.1130   0.5870   -12.858       0.0608  193.100    4   \n",
       "4            0.000000    0.1370   0.4450    -3.604       0.1060  169.881    1   \n",
       "..                ...       ...      ...       ...          ...      ...  ...   \n",
       "681          0.919000    0.0921   0.1460   -20.615       0.0603  129.736    0   \n",
       "682          0.120000    0.1400   0.1910    -7.351       0.0255   80.537   11   \n",
       "683          0.000000    0.0906   0.0799    -9.386       0.0545  124.099    4   \n",
       "684          0.000026    0.1120   0.2060   -15.099       0.0404  102.128    2   \n",
       "685          0.881000    0.0991   0.0804   -28.435       0.0397  140.179    0   \n",
       "\n",
       "     time_signature       mood  \n",
       "0                 4      Happy  \n",
       "1                 4        Sad  \n",
       "2                 4        Sad  \n",
       "3                 4      Happy  \n",
       "4                 4  Energetic  \n",
       "..              ...        ...  \n",
       "681               3       Calm  \n",
       "682               4        Sad  \n",
       "683               4        Sad  \n",
       "684               4        Sad  \n",
       "685               4       Calm  \n",
       "\n",
       "[686 rows x 19 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../songs/data_moods.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    197\n",
       "1    195\n",
       "2    154\n",
       "3    140\n",
       "Name: mood, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moods= {'Sad' : 0, 'Calm' : 1, 'Energetic' : 2, 'Happy' : 3}\n",
    "df['mood'] = df['mood'].apply(lambda x: moods[x])\n",
    "df['mood'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>length</th>\n",
       "      <th>danceability</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>key</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>379266</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.13700</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>-8.201</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>118.523</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>318800</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.01890</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>-5.069</td>\n",
       "      <td>0.0492</td>\n",
       "      <td>120.255</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>217946</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.91300</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.0934</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>-15.326</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>136.168</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>233000</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.08900</td>\n",
       "      <td>0.4380</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>-12.858</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>193.100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>268000</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.00171</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>-3.604</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>169.881</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>36</td>\n",
       "      <td>123066</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.96100</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.919000</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>-20.615</td>\n",
       "      <td>0.0603</td>\n",
       "      <td>129.736</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>5</td>\n",
       "      <td>435080</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.75700</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>-7.351</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>80.537</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>87</td>\n",
       "      <td>169265</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.78600</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.0799</td>\n",
       "      <td>-9.386</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>124.099</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>76</td>\n",
       "      <td>219146</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.91300</td>\n",
       "      <td>0.0848</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>-15.099</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>102.128</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>41</td>\n",
       "      <td>186331</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.0804</td>\n",
       "      <td>-28.435</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>140.179</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     popularity  length  danceability  acousticness  energy  instrumentalness  \\\n",
       "0            68  379266         0.866       0.13700  0.7300          0.000000   \n",
       "1            43  318800         0.381       0.01890  0.8320          0.196000   \n",
       "2            60  217946         0.346       0.91300  0.1390          0.000077   \n",
       "3             2  233000         0.466       0.08900  0.4380          0.000006   \n",
       "4            60  268000         0.419       0.00171  0.9320          0.000000   \n",
       "..          ...     ...           ...           ...     ...               ...   \n",
       "681          36  123066         0.402       0.96100  0.2360          0.919000   \n",
       "682           5  435080         0.452       0.75700  0.5150          0.120000   \n",
       "683          87  169265         0.642       0.78600  0.3740          0.000000   \n",
       "684          76  219146         0.561       0.91300  0.0848          0.000026   \n",
       "685          41  186331         0.377       0.99400  0.0156          0.881000   \n",
       "\n",
       "     liveness  valence  loudness  speechiness    tempo  key  time_signature  \n",
       "0      0.0843   0.6250    -8.201       0.0767  118.523    5               4  \n",
       "1      0.1530   0.1660    -5.069       0.0492  120.255    8               4  \n",
       "2      0.0934   0.1160   -15.326       0.0321  136.168    0               4  \n",
       "3      0.1130   0.5870   -12.858       0.0608  193.100    4               4  \n",
       "4      0.1370   0.4450    -3.604       0.1060  169.881    1               4  \n",
       "..        ...      ...       ...          ...      ...  ...             ...  \n",
       "681    0.0921   0.1460   -20.615       0.0603  129.736    0               3  \n",
       "682    0.1400   0.1910    -7.351       0.0255   80.537   11               4  \n",
       "683    0.0906   0.0799    -9.386       0.0545  124.099    4               4  \n",
       "684    0.1120   0.2060   -15.099       0.0404  102.128    2               4  \n",
       "685    0.0991   0.0804   -28.435       0.0397  140.179    0               4  \n",
       "\n",
       "[686 rows x 13 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['release_date'] = pd.to_datetime(df['release_date'])\n",
    "#df['release_year'] = df['release_date'].dt.year\n",
    "#df['release_month']= df['release_date'].dt.month\n",
    "#df['release_day']= df['release_date'].dt.day\n",
    "\n",
    "X = df.drop(['mood','id','name','album','artist','release_date'],axis=1)\n",
    "y = df['mood']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(548, 13)\n",
      "(138, 13)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: 0.8156296914095078\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "nn = MLPClassifier(max_iter = 15000, alpha=1.0, hidden_layer_sizes=8)\n",
    "scores = cross_val_score(nn, train_scaled, y_train, cv=5)\n",
    "print (\"cv score: \" + str(scores.mean()))\n",
    "\n",
    "hyper_opt = False\n",
    "if hyper_opt:\n",
    "    params = {\"alpha\": np.logspace(-4, 2, 7), 'hidden_layer_sizes': [1, 2, 5, 10, 20, 50, 100]}\n",
    "    clf = GridSearchCV(nn, params)\n",
    "    clf.fit(train_scaled, y_train)\n",
    "    print(\"hyperparam optimized score : \" + str(clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1.0, hidden_layer_sizes=100, max_iter=15000)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'hidden_layer_sizes': 100}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.59050488, 0.61053276, 0.69574094, 0.6633637 , 0.54342914,\n",
       "        0.70126796, 0.502635  , 0.53977108, 0.46534181, 0.57470298]),\n",
       " 'score_time': array([0.00032592, 0.00037813, 0.00035191, 0.00032425, 0.00032592,\n",
       "        0.00038886, 0.00031996, 0.00032687, 0.00030708, 0.00045609]),\n",
       " 'estimator': [MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000)],\n",
       " 'test_score': array([0.92727273, 0.74545455, 0.81818182, 0.87272727, 0.74545455,\n",
       "        0.87272727, 0.8       , 0.76363636, 0.81481481, 0.81481481]),\n",
       " 'train_score': array([0.84787018, 0.87018256, 0.86612576, 0.87018256, 0.87221095,\n",
       "        0.87018256, 0.86612576, 0.86815416, 0.8562753 , 0.86032389])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = cross_validate(nn, train_scaled, y_train, cv=10, return_train_score=True, return_estimator=True)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7898550724637681"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=8, max_iter=15000, alpha=1.0)\n",
    "nn.fit(train_scaled, y_train)\n",
    "test_preds = nn.predict(scaler.transform(X_test))\n",
    "accuracy_score(test_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./neural_network.joblib']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# safe  model\n",
    "joblib.dump(nn, \"./neural_network.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 2, 3, 0, 1, 2, 1, 0, 3, 0, 1, 2, 0, 0, 1, 3, 3, 1, 0, 0,\n",
       "       3, 2, 3, 0, 0, 1, 0, 2, 0, 1, 2, 3, 3, 3, 1, 1, 0, 1, 0, 2, 1, 0,\n",
       "       2, 1, 2, 2, 2, 0, 0, 2, 3, 3, 0, 1, 1, 3, 1, 2, 0, 1, 0, 1, 1, 2,\n",
       "       2, 0, 0, 2, 2, 0, 2, 2, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 2, 0, 3,\n",
       "       0, 1, 3, 3, 1, 2, 0, 2, 2, 3, 0, 1, 0, 2, 1, 0, 0, 1, 2, 2, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 2, 0, 3, 0, 2, 2, 0, 1, 1, 1, 3, 3, 2, 0, 1,\n",
       "       3, 1, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(scaler.transform(X_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see if we can leverage the accuracy with more data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ger more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = df.keys()\n",
    "keys =keys.to_list()\n",
    "#keys.remove('mood')\n",
    "\n",
    "sad_songs = pd.read_csv('../songs/very_sadSongs.csv',index_col=None)\n",
    "calm_songs = pd.read_csv('../songs/very_calmSongs.csv',index_col=None)\n",
    "energetic_songs = pd.read_csv('../songs/very_energeticSongs.csv',index_col=None)\n",
    "happy_songs = pd.read_csv('../songs/very_happySongs.csv',index_col=None)\n",
    "\n",
    "df_existing = df.copy()\n",
    "\n",
    "new_songs = [sad_songs, calm_songs, energetic_songs, happy_songs]\n",
    "moods = [0,1,2,3]\n",
    "\n",
    "for i in range(len(new_songs)):\n",
    "    new_df = new_songs[i]\n",
    "    new_df = new_df.reset_index(drop=True)\n",
    "    new_df['mood'] = moods[i]\n",
    "    df_existing = pd.concat([df_existing,new_df],ignore_index=True)\n",
    "    \n",
    "\n",
    "df_existing = df_existing.drop(['id','name','album','artist','release_date','Unnamed: 0'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_existing.drop(['mood'],axis=1)\n",
    "y = df_existing['mood']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: 0.7717300712461352\n",
      "hyperparam optimized score : 0.8088318322355155\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "nn = MLPClassifier(max_iter = 15000, alpha=1.0, hidden_layer_sizes=8)\n",
    "scores = cross_val_score(nn, train_scaled, y_train, cv=5)\n",
    "print (\"cv score: \" + str(scores.mean()))\n",
    "\n",
    "hyper_opt = True\n",
    "if hyper_opt:\n",
    "    params = {\"alpha\": np.logspace(-4, 2, 7), 'hidden_layer_sizes': [1, 2, 5, 10, 20, 50, 100]}\n",
    "    clf = GridSearchCV(nn, params)\n",
    "    clf.fit(train_scaled, y_train)\n",
    "    print(\"hyperparam optimized score : \" + str(clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1.0, hidden_layer_sizes=100, max_iter=15000)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'hidden_layer_sizes': 100}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.01678324, 0.796242  , 0.98170805, 1.02307606, 0.89058304,\n",
       "        1.00307989, 0.88434219, 0.93762207, 1.02510095, 1.03690481]),\n",
       " 'score_time': array([0.00037789, 0.00033998, 0.0003109 , 0.00045419, 0.00036883,\n",
       "        0.00032592, 0.00034094, 0.00030589, 0.00031996, 0.00033903]),\n",
       " 'estimator': [MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000),\n",
       "  MLPClassifier(alpha=1.0, hidden_layer_sizes=8, max_iter=15000)],\n",
       " 'test_score': array([0.73563218, 0.88505747, 0.75862069, 0.79069767, 0.76744186,\n",
       "        0.72093023, 0.79069767, 0.74418605, 0.8255814 , 0.75581395]),\n",
       " 'train_score': array([0.83118557, 0.81443299, 0.83376289, 0.82110682, 0.83397683,\n",
       "        0.84169884, 0.80952381, 0.84298584, 0.82882883, 0.83011583])}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = cross_validate(nn, train_scaled, y_train, cv=10, return_train_score=True, return_estimator=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8564814814814815"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=100, max_iter=15000, alpha=1.0)\n",
    "nn.fit(train_scaled, y_train)\n",
    "test_preds = nn.predict(scaler.transform(X_test))\n",
    "accuracy_score(test_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8564814814814815"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn2 = MLPClassifier(hidden_layer_sizes=100, max_iter=15000, alpha=1.0)\n",
    "nn2.fit(train_scaled, y_train)\n",
    "test_preds = nn.predict(scaler.transform(X_test))\n",
    "accuracy_score(test_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./neural_network_86.joblib']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# safe  model\n",
    "joblib.dump(nn, \"./neural_network_86.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
