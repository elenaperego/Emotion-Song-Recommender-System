{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take me down to the Paradise City\n",
      "Where the grass is green and the girls are pretty\n",
      "Take me home (I want you, please, take me home)\n",
      "Take me down to the Paradise City\n",
      "Where the grass is green and the girls are pretty\n",
      "Take me home (I want you, please, take me home)\n",
      "♪\n",
      "Just an urchin living under the street\n",
      "I'm a hard case that's tough to beat\n",
      "I'm your charity case so buy me somethin' to eat\n",
      "I'll pay you at another time\n",
      "Take it to the end of the line\n",
      "Rags and riches, or so they say, you gotta\n",
      "Keep pushing for the fortune and fame\n",
      "You know it's, it's all a gamble when it's just a game\n",
      "You treat it like a capital crime\n",
      "Everybody's doing their time\n",
      "Take me down to the Paradise City\n",
      "Where the grass is green and the girls are pretty\n",
      "Oh, won't you please take me home? Yeah-yeah\n",
      "Take me down to the Paradise City\n",
      "Where the grass is green and the girls are pretty\n",
      "Take me home\n",
      "Strapped in the chair of the city's gas chamber\n",
      "Why I'm here, I can't quite remember\n",
      "The surgeon general says it's hazardous to breathe\n",
      "I'd have another cigarette but I can't see\n",
      "Tell me, who you're gonna believe?\n",
      "Take me down to the Paradise City\n",
      "Where the grass is green and the girls are pretty\n",
      "Take me home, yeah-yeah\n",
      "Take me down to the Paradise City\n",
      "Where the grass is green and the girls are pretty\n",
      "I want you, please, take me home\n",
      "Yeah\n",
      "So far away\n",
      "So far away\n",
      "So far away\n",
      "So far away\n",
      "Captain America's been torn apart now\n",
      "He's a court jester with a broken heart\n",
      "He said, \"Turn me around and take me back to the start\"\n",
      "I must be losin' my mind, \"Are you blind?\"\n",
      "\"I've seen it all a million times\"\n",
      "Take me down to the Paradise City\n",
      "Where the grass is green and the girls are pretty\n",
      "Take me home, yeah-yeah\n",
      "Take me down to the Paradise City\n",
      "Where the grass is green and the girls are pretty\n",
      "I want you, please, take me home\n",
      "Take me down to the Paradise City\n",
      "Where the grass is green and the girls are pretty\n",
      "Take me home, yeah-yeah\n",
      "Take me down to the Paradise City\n",
      "Where the grass is green and the girls are pretty\n",
      "Oh, won't you please take me home?\n",
      "Home\n",
      "♪\n",
      "I wanna go, I wanna know\n",
      "I want you, please, take me home\n",
      "I wanna see how good it can be\n",
      "I want you, please, take me home\n",
      "Take me down to the Paradise City\n",
      "Where the grass is green and the girls are pretty\n",
      "Take me home (I want you, please, take me home)\n",
      "Take me down to the Paradise City\n",
      "Where the grass is green and the girls are pretty\n",
      "I want you, please, take me home\n",
      "Take me down, ooh yeah, spin me 'round\n",
      "Oh, won't you please take me home?\n",
      "I wanna see how good it can be\n",
      "I want you, please, take me home\n",
      "♪\n",
      "I wanna see how good it can be\n",
      "Oh, oh, take me home\n",
      "Take me down to the Paradise City\n",
      "Where the grass is green and the girls are pretty\n",
      "I want you, please, take me home (I want you, I want you take me home)\n",
      "I wanna go (I wanna), I wanna know (I wanna)\n",
      "I want you, please, take me home\n",
      "Baby, yeah\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spotify_lyrics_scraper as spotify\n",
    "\n",
    "# Ottieni il token SP_DC\n",
    "token = spotify.getToken(\"AQBSz33_ODmldHiskIdlUiuu4yS92-tR4swS5FeqJuHYfBNUdEs3j0mWK4Hmo9wDc3eTK6IRAE0xFoXnH94CkXHKUWvZuFLTdTxyBdOhLCtSyhZLRWM21tgwJDAI1MxFAA_dEPWMtVMxGd9GefWoL4JbtxCXlsfKvk0CF5zpBQ1m_JskXi7hHLj-wLJBlNdTlpdkeA_LZwBCZG5yQowbiE4hO8K5\")\n",
    "\n",
    "# Ottieni i testi della canzone\n",
    "lyrics_data = spotify.getLyrics(token, songName=\"Paradise city\")\n",
    "\n",
    "# Controlla se la richiesta è andata a buon fine\n",
    "if lyrics_data['status']:\n",
    "    # Estrai le linee di testo\n",
    "    lyrics_lines = lyrics_data['message']['lyrics']['lines']\n",
    "    \n",
    "    # Stampa solo il testo della canzone\n",
    "    for line in lyrics_lines:\n",
    "        print(line['words'])\n",
    "else:\n",
    "    print(\"Errore nel recupero dei testi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classification:\n",
      "\n",
      "Pain: 0.3304\n",
      "Anger: 0.1785\n",
      "Caring: 0.1659\n",
      "Admiration: 0.1429\n",
      "Amusement: 0.0889\n",
      "Confusion: 0.0545\n",
      "Love: 0.0389\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Combine all the lyrics lines into a single string\n",
    "song_lyrics = \"\\n\".join([line['words'] for line in lyrics_lines])\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(song_lyrics, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# Get the model outputs\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Extract logits and compute probabilities\n",
    "logits = outputs.logits\n",
    "probabilities = torch.nn.functional.softmax(logits, dim=1)[0]\n",
    "\n",
    "# Define the emotions\n",
    "emotions = [\n",
    "    'admiration',\n",
    "    'amusement',\n",
    "    'anger',\n",
    "    'love',\n",
    "    'pain',\n",
    "    'caring',\n",
    "    'confusion'\n",
    "]\n",
    "\n",
    "# Map emotions to probabilities\n",
    "emotion_probs = {emotion: float(probabilities[idx]) for idx, emotion in enumerate(emotions)}\n",
    "\n",
    "# Sort emotions by probability in descending order\n",
    "sorted_emotions = sorted(emotion_probs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the emotions and their corresponding probabilities\n",
    "print(\"Emotion Classification:\\n\")\n",
    "for emotion, prob in sorted_emotions:\n",
    "    print(f\"{emotion.capitalize()}: {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classification:\n",
      "\n",
      "Positive: 0.2419\n",
      "Joy: 0.2097\n",
      "Anticipation: 0.1774\n",
      "Surprise: 0.1290\n",
      "Trust: 0.1129\n",
      "Sadness: 0.0645\n",
      "Fear: 0.0484\n",
      "Negative: 0.0161\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import spotify_lyrics_scraper as spotify\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "\n",
    "\n",
    "# Function to load the NRC Emotion Lexicon\n",
    "def load_nrc_lexicon(local_path='NRC-Emotion-Lexicon-Wordlevel-v0.92.txt'):\n",
    "    emotion_dict = defaultdict(set)\n",
    "    with open(local_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 3:\n",
    "                word, emotion, association = parts\n",
    "                if int(association) > 0:\n",
    "                    emotion_dict[emotion].add(word)\n",
    "    return emotion_dict\n",
    "\n",
    "# Obtain the SP_DC token\n",
    "token = spotify.getToken(\"AQBSz33_ODmldHiskIdlUiuu4yS92-tR4swS5FeqJuHYfBNUdEs3j0mWK4Hmo9wDc3eTK6IRAE0xFoXnH94CkXHKUWvZuFLTdTxyBdOhLCtSyhZLRWM21tgwJDAI1MxFAA_dEPWMtVMxGd9GefWoL4JbtxCXlsfKvk0CF5zpBQ1m_JskXi7hHLj-wLJBlNdTlpdkeA_LZwBCZG5yQowbiE4hO8K5\")\n",
    "# Replace with your actual token\n",
    "\n",
    "# Obtain the lyrics of the song\n",
    "lyrics_data = spotify.getLyrics(token, songName=\"Dancing Queen\")\n",
    "\n",
    "# Check if the request was successful\n",
    "if lyrics_data['status']:\n",
    "    # Extract the lyrics lines\n",
    "    lyrics_lines = lyrics_data['message']['lyrics']['lines']\n",
    "    \n",
    "    # Combine the lyrics into a single string\n",
    "    song_lyrics = '\\n'.join([line['words'] for line in lyrics_lines])\n",
    "    \n",
    "    # Tokenize the song lyrics\n",
    "    tokens = word_tokenize(song_lyrics.lower())\n",
    "    \n",
    "    # Load the lexicon\n",
    "    emotion_lexicon = load_nrc_lexicon()\n",
    "    \n",
    "    # Count the emotions\n",
    "    emotion_counts = defaultdict(int)\n",
    "    for token in tokens:\n",
    "        for emotion, words in emotion_lexicon.items():\n",
    "            if token in words:\n",
    "                emotion_counts[emotion] += 1\n",
    "    \n",
    "    # Total words matched\n",
    "    total_emotion_words = sum(emotion_counts.values())\n",
    "    \n",
    "    # Calculate emotion percentages\n",
    "    emotion_percentages = {emotion: (count / total_emotion_words) if total_emotion_words > 0 else 0 for emotion, count in emotion_counts.items()}\n",
    "    \n",
    "    # Sort emotions by percentage\n",
    "    sorted_emotions = sorted(emotion_percentages.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Emotion Classification:\\n\")\n",
    "    for emotion, percentage in sorted_emotions:\n",
    "        print(f\"{emotion.capitalize()}: {percentage:.4f}\")\n",
    "else:\n",
    "    print(\"Errore nel recupero dei testi.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial Recognition with DLIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized as: Vito\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "\n",
    "# Load dlib's face detector and face recognition model\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')  # Download this model file from dlib\n",
    "face_rec_model = dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')  # Download this too\n",
    "\n",
    "# List to store face encodings and corresponding labels (names)\n",
    "known_face_encodings = []\n",
    "known_face_labels = []\n",
    "\n",
    "# Load and encode your database of faces (use your database here)\n",
    "def load_known_faces():\n",
    "    # Example: You have images and labels in a folder (replace with your actual data loading logic)\n",
    "    # For each face image, detect the face, encode it, and store the encoding with the label (name)\n",
    "    images = ['/Users/vittoriomocchi/Documents/Vitos/Projects/Emotion-Song-Recommender-System-main/database/Elena.jpg', '/Users/vittoriomocchi/Documents/Vitos/Projects/Emotion-Song-Recommender-System-main/database/Lena.jpg', '/Users/vittoriomocchi/Documents/Vitos/Projects/Emotion-Song-Recommender-System-main/database/Meli.jpg', '/Users/vittoriomocchi/Documents/Vitos/Projects/Emotion-Song-Recommender-System-main/database/Mischa.jpg', '/Users/vittoriomocchi/Documents/Vitos/Projects/Emotion-Song-Recommender-System-main/database/Vito.jpg' ]  # replace with your image paths\n",
    "    labels = ['Elena', 'Lena', 'Meli', 'Mischa', 'Vito']  # replace with your corresponding names\n",
    "    \n",
    "    for img_path, label in zip(images, labels):\n",
    "        image = cv2.imread(img_path)\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray_image)\n",
    "\n",
    "        if len(faces) > 0:\n",
    "            face = faces[0]  # Use the first detected face\n",
    "            shape = predictor(gray_image, face)\n",
    "            face_encoding = np.array(face_rec_model.compute_face_descriptor(image, shape))\n",
    "\n",
    "            # Add the face encoding and label to the lists\n",
    "            known_face_encodings.append(face_encoding)\n",
    "            known_face_labels.append(label)\n",
    "\n",
    "# Recognize the face from an input image\n",
    "def recognize_face(input_image_path):\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "    gray_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray_image)\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        face = faces[0]\n",
    "        shape = predictor(gray_image, face)\n",
    "        input_face_encoding = np.array(face_rec_model.compute_face_descriptor(input_image, shape))\n",
    "\n",
    "        # Compare with known faces\n",
    "        distances = np.linalg.norm(known_face_encodings - input_face_encoding, axis=1)\n",
    "        min_distance_idx = np.argmin(distances)\n",
    "\n",
    "        if distances[min_distance_idx] < 0.6:  # Threshold for recognition\n",
    "            return known_face_labels[min_distance_idx]\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    return \"No face detected\"\n",
    "\n",
    "# Load the known faces (your database)\n",
    "load_known_faces()\n",
    "\n",
    "# Now let's recognize a face from a new image\n",
    "recognized_name = recognize_face('/Users/vittoriomocchi/Documents/Vitos/Projects/Emotion-Song-Recommender-System-main/IMG_5720.jpg')  # replace with the path to the image of you\n",
    "\n",
    "print(f\"Recognized as: {recognized_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected emotion: sad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "# Detect emotions from the input image\n",
    "def recognize_emotion(input_image_path):\n",
    "    result = DeepFace.analyze(img_path=input_image_path, actions=['emotion'])\n",
    "    return result[0][\"dominant_emotion\"]\n",
    "\n",
    "# Detect emotions from the image\n",
    "recognized_emotion = recognize_emotion('/Users/vittoriomocchi/Documents/Vitos/Projects/Emotion-Song-Recommender-System-main/IMG_5720.jpg')\n",
    "\n",
    "print(f\"Detected emotion: {recognized_emotion}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to API Spotify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Everyday Hustle by Future, Metro Boomin, Rick Ross\n",
      "2. New Soul by Yael Naim\n",
      "3. Dancing in the Moonlight by Toploader\n",
      "4. Need U 2Nite (feat. Massimo Pericolo) by Guè, Massimo Pericolo\n",
      "5. Angelina Jolie by Bresh, SHUNE\n",
      "6. Suga Honey Iced Tea by Kelis\n",
      "7. Afraid To Feel by LF SYSTEM\n",
      "8. Con il nastro rosa by Lucio Battisti\n",
      "9. Diventare Grande by Guè\n",
      "10. Alright - Remastered 2013 by Jamiroquai\n",
      "11. La Maritza by Sylvie Vartan\n",
      "12. Nice For What by Drake\n",
      "13. Dubbi non ho - 2017 Remaster by Pino Daniele\n",
      "14. Senz E Me by Geolier\n",
      "15. Beat It by Future, Metro Boomin\n",
      "16. Rainfall (Praise You) by Tom Santa\n",
      "17. My Oh My (feat. DaBaby) by Camila Cabello, DaBaby\n",
      "18. Not Like Us by Kendrick Lamar\n",
      "19. L'appuntamento by Ornella Vanoni\n",
      "20. West Coast (feat. Blueface, ALLBLACK & YG) by G-Eazy, Blueface, ALLBLACK, YG\n"
     ]
    }
   ],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "\n",
    "# Set up authentication\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=\"ca5e1837d17442e1b5c842377539f4fb\",\n",
    "                                               client_secret=\"c97c23c09b7948b4b4f4025a08a15a39\",\n",
    "                                               redirect_uri=\"http://localhost:8888/callback\",\n",
    "                                               scope=\"user-top-read\"))\n",
    "\n",
    "# Get the current user's top tracks\n",
    "top_tracks = sp.current_user_top_tracks(limit=20, offset=0, time_range='medium_term')\n",
    "\n",
    "# Print the top tracks\n",
    "for idx, track in enumerate(top_tracks['items']):\n",
    "    print(f\"{idx + 1}. {track['name']} by {', '.join(artist['name'] for artist in track['artists'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. elenaperego + Solosoldi - 50 tracks\n",
      "2. My recommendation playlist - 10 tracks\n",
      "3. Reggaeton heroine - 15 tracks\n",
      "4. Best Guitar Intros Ever - 119 tracks\n",
      "5. Tatuz - 38 tracks\n",
      "6. V - 64 tracks\n",
      "7. non mi piacciono le voci femminili ma - 127 tracks\n"
     ]
    }
   ],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "\n",
    "# Set up authentication with the additional scope\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=\"ca5e1837d17442e1b5c842377539f4fb\",\n",
    "                                               client_secret=\"c97c23c09b7948b4b4f4025a08a15a39\",\n",
    "                                               redirect_uri=\"http://localhost:8888/callback\",\n",
    "                                               scope=\"user-top-read playlist-read-private\"))\n",
    "\n",
    "# Get the current user's private playlists\n",
    "playlists = sp.current_user_playlists()\n",
    "\n",
    "# Print the playlists\n",
    "for idx, playlist in enumerate(playlists['items']):\n",
    "    print(f\"{idx + 1}. {playlist['name']} - {playlist['tracks']['total']} tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
