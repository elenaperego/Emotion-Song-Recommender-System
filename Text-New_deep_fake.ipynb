{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm coming out of my cage, and I've been doing just fine\n",
      "Gotta, gotta be down because I want it all\n",
      "It started out with a kiss, how did it end up like this?\n",
      "It was only a kiss, it was only a kiss\n",
      "Now I'm falling asleep, and she's calling a cab\n",
      "While he's having a smoke, and she's taking a drag\n",
      "Now they're going to bed, and my stomach is sick\n",
      "And it's all in my head, but she's touching his\n",
      "Chest now, he takes off her dress now\n",
      "Let me go\n",
      "♪\n",
      "I just can't look, it's killing me\n",
      "And taking control\n",
      "Jealousy, turning saints into the sea\n",
      "Swimming through sick lullabies, choking on your alibis\n",
      "But it's just the price I pay, destiny is calling me\n",
      "Open up my eager eyes, 'cause I'm Mr. Brightside\n",
      "♪\n",
      "I'm coming out of my cage, and I've been doing just fine\n",
      "Gotta, gotta be down because I want it all\n",
      "It started out with a kiss, how did it end up like this?\n",
      "It was only a kiss, it was only a kiss\n",
      "Now I'm falling asleep, and she's calling a cab\n",
      "While he's having a smoke, and she's taking a drag\n",
      "Now they're going to bed, and my stomach is sick\n",
      "And it's all in my head, but she's touching his\n",
      "Chest now, he takes off her dress now\n",
      "Let me go\n",
      "♪\n",
      "'Cause I just can't look, it's killing me\n",
      "And taking control\n",
      "Jealousy, turning saints into the sea\n",
      "Swimming through sick lullabies, choking on your alibis\n",
      "But it's just the price I pay, destiny is calling me\n",
      "Open up my eager eyes, 'cause I'm Mr. Brightside\n",
      "♪\n",
      "I never\n",
      "I never\n",
      "I never\n",
      "I never\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spotify_lyrics_scraper as spotify\n",
    "\n",
    "# Ottieni il token\n",
    "token = spotify.getToken(\"AQBSz33_ODmldHiskIdlUiuu4yS92-tR4swS5FeqJuHYfBNUdEs3j0mWK4Hmo9wDc3eTK6IRAE0xFoXnH94CkXHKUWvZuFLTdTxyBdOhLCtSyhZLRWM21tgwJDAI1MxFAA_dEPWMtVMxGd9GefWoL4JbtxCXlsfKvk0CF5zpBQ1m_JskXi7hHLj-wLJBlNdTlpdkeA_LZwBCZG5yQowbiE4hO8K5\")\n",
    "\n",
    "# Ottieni i testi della canzone\n",
    "lyrics_data = spotify.getLyrics(token, songName=\"Mr Brightside\")\n",
    "\n",
    "# Controlla se la richiesta è andata a buon fine\n",
    "if lyrics_data['status']:\n",
    "    # Estrai le linee di testo\n",
    "    lyrics_lines = lyrics_data['message']['lyrics']['lines']\n",
    "    \n",
    "    # Stampa solo il testo della canzone\n",
    "    for line in lyrics_lines:\n",
    "        print(line['words'])\n",
    "else:\n",
    "    print(\"Errore nel recupero dei testi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29950f210e3f4a2fbc1d8627ba72d50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/294 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ff2d78f58445c4947d98e57b1542da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f494433416724d15aad1132c3af2663b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ee7d7cdebf499e8299708c215b33ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9470fd329e7a4a53bd601454ea1cc294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284ff5229fe44083aff656d8186138e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ElenaPerego/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f20e1156bb24e768e3f8cb37ffae973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Classification:\n",
      "\n",
      "Caring: 0.2751\n",
      "Pain: 0.2427\n",
      "Confusion: 0.2308\n",
      "Anger: 0.1135\n",
      "Love: 0.0595\n",
      "Admiration: 0.0515\n",
      "Amusement: 0.0269\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Combine all the lyrics lines into a single string\n",
    "song_lyrics = \"\\n\".join([line['words'] for line in lyrics_lines])\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(song_lyrics, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# Get the model outputs\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Extract logits and compute probabilities\n",
    "logits = outputs.logits\n",
    "probabilities = torch.nn.functional.softmax(logits, dim=1)[0]\n",
    "\n",
    "# Define the emotions\n",
    "emotions = [\n",
    "    'admiration',\n",
    "    'amusement',\n",
    "    'anger',\n",
    "    'love',\n",
    "    'pain',\n",
    "    'caring',\n",
    "    'confusion'\n",
    "]\n",
    "\n",
    "# Map emotions to probabilities\n",
    "emotion_probs = {emotion: float(probabilities[idx]) for idx, emotion in enumerate(emotions)}\n",
    "\n",
    "# Sort emotions by probability in descending order\n",
    "sorted_emotions = sorted(emotion_probs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the emotions and their corresponding probabilities\n",
    "print(\"Emotion Classification:\\n\")\n",
    "for emotion, prob in sorted_emotions:\n",
    "    print(f\"{emotion.capitalize()}: {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial Recognition with DLIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized as: Vito\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "\n",
    "# Load dlib's face detector and face recognition model\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')  # Download this model file from dlib\n",
    "face_rec_model = dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')  # Download this too\n",
    "\n",
    "# List to store face encodings and corresponding labels (names)\n",
    "known_face_encodings = []\n",
    "known_face_labels = []\n",
    "\n",
    "# Load and encode your database of faces (use your database here)\n",
    "def load_known_faces():\n",
    "    # Example: You have images and labels in a folder (replace with your actual data loading logic)\n",
    "    # For each face image, detect the face, encode it, and store the encoding with the label (name)\n",
    "    images = ['/Users/vittoriomocchi/Documents/Vitos/Projects/Emotion-Song-Recommender-System-main/database/Elena.jpg', '/Users/vittoriomocchi/Documents/Vitos/Projects/Emotion-Song-Recommender-System-main/database/Lena.jpg', '/Users/vittoriomocchi/Documents/Vitos/Projects/Emotion-Song-Recommender-System-main/database/Meli.jpg', '/Users/vittoriomocchi/Documents/Vitos/Projects/Emotion-Song-Recommender-System-main/database/Mischa.jpg', '/Users/vittoriomocchi/Documents/Vitos/Projects/Emotion-Song-Recommender-System-main/database/Vito.jpg' ]  # replace with your image paths\n",
    "    labels = ['Elena', 'Lena', 'Meli', 'Mischa', 'Vito']  # replace with your corresponding names\n",
    "    \n",
    "    for img_path, label in zip(images, labels):\n",
    "        image = cv2.imread(img_path)\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray_image)\n",
    "\n",
    "        if len(faces) > 0:\n",
    "            face = faces[0]  # Use the first detected face\n",
    "            shape = predictor(gray_image, face)\n",
    "            face_encoding = np.array(face_rec_model.compute_face_descriptor(image, shape))\n",
    "\n",
    "            # Add the face encoding and label to the lists\n",
    "            known_face_encodings.append(face_encoding)\n",
    "            known_face_labels.append(label)\n",
    "\n",
    "# Recognize the face from an input image\n",
    "def recognize_face(input_image_path):\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "    gray_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray_image)\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        face = faces[0]\n",
    "        shape = predictor(gray_image, face)\n",
    "        input_face_encoding = np.array(face_rec_model.compute_face_descriptor(input_image, shape))\n",
    "\n",
    "        # Compare with known faces\n",
    "        distances = np.linalg.norm(known_face_encodings - input_face_encoding, axis=1)\n",
    "        min_distance_idx = np.argmin(distances)\n",
    "\n",
    "        if distances[min_distance_idx] < 0.6:  # Threshold for recognition\n",
    "            return known_face_labels[min_distance_idx]\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    return \"No face detected\"\n",
    "\n",
    "# Load the known faces (your database)\n",
    "load_known_faces()\n",
    "\n",
    "# Now let's recognize a face from a new image\n",
    "recognized_name = recognize_face('/Users/vittoriomocchi/Documents/Vitos/Projects/Emotion-Song-Recommender-System-main/IMG_5720.jpg')  # replace with the path to the image of you\n",
    "\n",
    "print(f\"Recognized as: {recognized_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected emotion: sad\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "# Detect emotions from the input image\n",
    "def recognize_emotion(input_image_path):\n",
    "    result = DeepFace.analyze(img_path=input_image_path, actions=['emotion'])\n",
    "    return result[0][\"dominant_emotion\"]\n",
    "\n",
    "# Detect emotions from the image\n",
    "recognized_emotion = recognize_emotion('/Users/vittoriomocchi/Documents/Vitos/Projects/Emotion-Song-Recommender-System-main/IMG_5720.jpg')\n",
    "\n",
    "print(f\"Detected emotion: {recognized_emotion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
